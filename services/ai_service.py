"""
ORBIT - AI Service
ServiÃ§o de IA com Personalidade "Coach Brasileiro"

Suporta:
- Ollama (Local - Llama 3, Mistral)
- Groq Cloud (Free Tier - Llama 3)
- Fallback para respostas sem IA
"""

import os
import json
import httpx
from typing import Optional, Dict, List, AsyncGenerator
from datetime import datetime
from enum import Enum
import asyncio

from app.services.financial_engine import analisar_transacao_para_ia


class AIProvider(Enum):
    """Provedores de IA suportados"""
    OLLAMA = "ollama"
    GROQ = "groq"
    FALLBACK = "fallback"


# ============================================
# ðŸ§  SYSTEM PROMPT - ALMA DO ORBIT
# ============================================

SYSTEM_PROMPT_ORBIT = """VocÃª Ã© o ORBIT, um assistente financeiro pessoal brasileiro.

**Sua Identidade:**
Jovem, moderno, fala de forma direta e usa gÃ­rias leves do Brasil (tipo 'mano', 'bora', 'ficou caro', 'daora', 'tranquilo', 'suave'). VocÃª NÃƒO Ã© um robÃ´ chato de banco. VocÃª Ã© um parceiro que realmente se importa com a saÃºde financeira do usuÃ¡rio.

**Suas Diretrizes PrimÃ¡rias:**

1. **AnÃ¡lise de Sentimento Financeiro:** 
   Antes de responder, SEMPRE verifique o estado financeiro atual do usuÃ¡rio (se ele estÃ¡ endividado ou com saldo positivo). Use essa informaÃ§Ã£o para adaptar seu tom.

2. **Modo 'No Vermelho' (DÃ­vida):** 
   Se o usuÃ¡rio gastar algo supÃ©rfluo enquanto estiver endividado, dÃª uma 'bronca amigÃ¡vel'. Mostre o custo de oportunidade.
   Exemplos:
   - "Cara, essa pizza de R$60 te custou mais 2 dias pagando juros pro banco. Bora focar?"
   - "AÃ­ nÃ£o, mano! Esse gasto atrasou sua liberdade em 3 dias. Valeu mesmo a pena?"
   - "Opa, pera aÃ­. Com dÃ­vida, cada real conta. Esse gasto te custou X dias a mais."

3. **Modo 'No Verde' (Positivo):** 
   Se o usuÃ¡rio tiver saldo, celebre conquistas, mas incentive a consistÃªncia.
   Exemplos:
   - "AÃ­ sim! Mandou bem na economia essa semana. Pode pedir aquele lanche, vocÃª merece hoje."
   - "Boa! Sobrou grana esse mÃªs. Bora guardar uma parte?"
   - "Daora demais! Continua assim que a liberdade tÃ¡ chegando!"

4. **EducaÃ§Ã£o Curta:** 
   Nunca dÃª palestras longas. DÃª dicas financeiras em 1 ou 2 frases no mÃ¡ximo, sempre atreladas Ã  aÃ§Ã£o atual dele.

5. **Espelhamento:** 
   Se o usuÃ¡rio usar muita gÃ­ria, use mais gÃ­ria. Se ele for mais formal, seja um pouco mais formal (mas nunca como banco).

6. **Empatia Real:**
   ReconheÃ§a que gerenciar dinheiro Ã© difÃ­cil. NÃ£o julgue, ajude.

**Formato de Resposta:**
- Respostas CURTAS (mÃ¡ximo 2-3 frases)
- Use emojis com moderaÃ§Ã£o (1-2 por mensagem)
- Sempre que possÃ­vel, inclua o IMPACTO REAL do gasto/ganho

**Seu Objetivo Final:** 
Fazer o usuÃ¡rio quitar as dÃ­vidas o mais rÃ¡pido possÃ­vel e sentir que tem um parceiro controlando a grana com ele. VocÃª comemora vitÃ³rias e dÃ¡ aquele toque quando ele vacila."""


# ============================================
# ðŸ“ PROMPT TEMPLATES
# ============================================

def build_context_prompt(
    mensagem_usuario: str,
    contexto_financeiro: Dict,
    historico: List[Dict] = None
) -> str:
    """
    ConstrÃ³i o prompt com contexto financeiro para a IA
    """
    saldo = contexto_financeiro.get("saldo_atual", 0)
    divida = contexto_financeiro.get("divida_total", 0)
    status = "no vermelho ðŸ”´" if saldo < 0 or divida > 0 else "no verde ðŸŸ¢"
    
    impacto_texto = ""
    if contexto_financeiro.get("impacto"):
        imp = contexto_financeiro["impacto"]
        impacto_texto = f"""
**IMPACTO DO ÃšLTIMO GASTO:**
- Dias adicionais de dÃ­vida: {imp.get('dias_adicionais', 0)}
- Custo real com juros: R${imp.get('custo_real', 0):.2f}
"""

    contexto = f"""
**CONTEXTO FINANCEIRO ATUAL DO USUÃRIO:**
- Saldo atual: R${saldo:.2f}
- DÃ­vida total: R${divida:.2f}
- Status: {status}
{impacto_texto}

**MENSAGEM DO USUÃRIO:**
{mensagem_usuario}

Responda como o ORBIT, seguindo suas diretrizes. Seja BREVE e DIRETO.
"""
    return contexto


# ============================================
# ðŸ”Œ PROVIDERS DE IA
# ============================================

class OllamaProvider:
    """Provider para Ollama (Local)"""
    
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.model = os.getenv("OLLAMA_MODEL", "llama3:8b")
    
    async def is_available(self) -> bool:
        """Verifica se Ollama estÃ¡ rodando"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{self.base_url}/api/tags", timeout=2.0)
                return response.status_code == 200
        except:
            return False
    
    async def generate(
        self, 
        prompt: str, 
        system: str = SYSTEM_PROMPT_ORBIT
    ) -> str:
        """Gera resposta usando Ollama"""
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "system": system,
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "top_p": 0.9,
                        "num_predict": 256  # Respostas curtas
                    }
                },
                timeout=30.0
            )
            data = response.json()
            return data.get("response", "")
    
    async def generate_stream(
        self, 
        prompt: str, 
        system: str = SYSTEM_PROMPT_ORBIT
    ) -> AsyncGenerator[str, None]:
        """Gera resposta em streaming"""
        async with httpx.AsyncClient() as client:
            async with client.stream(
                "POST",
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "system": system,
                    "stream": True,
                    "options": {
                        "temperature": 0.7,
                        "num_predict": 256
                    }
                },
                timeout=60.0
            ) as response:
                async for line in response.aiter_lines():
                    if line:
                        data = json.loads(line)
                        if "response" in data:
                            yield data["response"]


class GroqProvider:
    """Provider para Groq Cloud (Free Tier)"""
    
    def __init__(self):
        self.api_key = os.getenv("GROQ_API_KEY")
        self.base_url = "https://api.groq.com/openai/v1"
        self.model = "llama-3.1-8b-instant"  # Free tier
    
    async def is_available(self) -> bool:
        """Verifica se API key estÃ¡ configurada"""
        return bool(self.api_key)
    
    async def generate(
        self, 
        prompt: str, 
        system: str = SYSTEM_PROMPT_ORBIT
    ) -> str:
        """Gera resposta usando Groq"""
        if not self.api_key:
            raise ValueError("GROQ_API_KEY nÃ£o configurada")
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.base_url}/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.model,
                    "messages": [
                        {"role": "system", "content": system},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.7,
                    "max_tokens": 256
                },
                timeout=30.0
            )
            data = response.json()
            return data["choices"][0]["message"]["content"]


class FallbackProvider:
    """
    Provider de fallback quando nenhuma IA estÃ¡ disponÃ­vel
    Usa respostas prÃ©-definidas baseadas em contexto
    """
    
    RESPOSTAS_VERMELHO = [
        "AÃ­ nÃ£o, mano! ðŸ”´ Enquanto tiver dÃ­vida, cada gasto conta. Bora focar na quitaÃ§Ã£o?",
        "Opa, pera aÃ­! Com dÃ­vida rolando, esse gasto te atrasa. Valeu mesmo a pena?",
        "Cara, sei que Ã© difÃ­cil, mas tamo no vermelho. Bora segurar um pouco?",
        "ðŸ”´ Gastinho aqui, gastinho ali... e a dÃ­vida sÃ³ cresce. Bora apertar o cinto?"
    ]
    
    RESPOSTAS_VERDE = [
        "Boa! ðŸŸ¢ TÃ¡ sobrando grana, mas lembra de guardar uma parte, hein!",
        "Daora! Pode gastar, mas sem loucura. ConsistÃªncia Ã© o segredo! ðŸ’ª",
        "AÃ­ sim! TÃ¡ no verde. Aproveita, mas com consciÃªncia!",
        "ðŸŸ¢ Mandou bem! Continua assim que a liberdade financeira tÃ¡ chegando!"
    ]
    
    RESPOSTAS_NEUTRAS = [
        "Beleza, registrei aqui! Bora manter o controle? ðŸ“Š",
        "Anotado! Qualquer coisa, tÃ´ aqui pra ajudar.",
        "Tranquilo! Lembra que cada centavo conta, hein!",
        "Fechado! Bora acompanhar juntos essa grana."
    ]
    
    async def is_available(self) -> bool:
        return True
    
    async def generate(
        self, 
        prompt: str, 
        system: str = "",
        contexto: Dict = None
    ) -> str:
        """Gera resposta baseada em regras simples"""
        import random
        
        if contexto:
            saldo = contexto.get("saldo_atual", 0)
            divida = contexto.get("divida_total", 0)
            
            if divida > 0 or saldo < 0:
                return random.choice(self.RESPOSTAS_VERMELHO)
            elif saldo > 0:
                return random.choice(self.RESPOSTAS_VERDE)
        
        return random.choice(self.RESPOSTAS_NEUTRAS)


# ============================================
# ðŸŽ¯ SERVIÃ‡O PRINCIPAL
# ============================================

class AIService:
    """
    ServiÃ§o principal de IA do ORBIT
    Gerencia providers e fallbacks
    """
    
    def __init__(self):
        self.ollama = OllamaProvider()
        self.groq = GroqProvider()
        self.fallback = FallbackProvider()
        self.current_provider: Optional[AIProvider] = None
    
    async def initialize(self):
        """Detecta e inicializa o melhor provider disponÃ­vel"""
        # Prioridade: Ollama (local) > Groq (cloud) > Fallback
        if await self.ollama.is_available():
            self.current_provider = AIProvider.OLLAMA
            print("ðŸ§  AI Provider: Ollama (Local)")
        elif await self.groq.is_available():
            self.current_provider = AIProvider.GROQ
            print("ðŸ§  AI Provider: Groq Cloud")
        else:
            self.current_provider = AIProvider.FALLBACK
            print("ðŸ§  AI Provider: Fallback (Respostas PrÃ©-definidas)")
        
        return self.current_provider
    
    async def processar_mensagem(
        self,
        mensagem: str,
        contexto_financeiro: Dict,
        historico: List[Dict] = None
    ) -> Dict:
        """
        Processa uma mensagem do usuÃ¡rio e retorna resposta da IA
        """
        # Construir prompt com contexto
        prompt = build_context_prompt(mensagem, contexto_financeiro, historico)
        
        # Gerar resposta baseado no provider
        try:
            if self.current_provider == AIProvider.OLLAMA:
                resposta = await self.ollama.generate(prompt)
            elif self.current_provider == AIProvider.GROQ:
                resposta = await self.groq.generate(prompt)
            else:
                resposta = await self.fallback.generate(
                    prompt, 
                    contexto=contexto_financeiro
                )
        except Exception as e:
            print(f"âš ï¸ Erro no AI Provider: {e}")
            # Fallback em caso de erro
            resposta = await self.fallback.generate(
                prompt, 
                contexto=contexto_financeiro
            )
        
        return {
            "resposta": resposta,
            "provider": self.current_provider.value,
            "timestamp": datetime.now().isoformat()
        }
    
    async def classificar_transacao(self, texto: str) -> Dict:
        """
        Usa IA para classificar texto em tipo de transaÃ§Ã£o
        
        Returns:
            Dict com tipo (receita/despesa/conversa), categoria e valor
        """
        prompt_classificacao = f"""
Analise o texto abaixo e extraia informaÃ§Ãµes financeiras:

TEXTO: "{texto}"

Responda APENAS com um JSON vÃ¡lido:
{{
    "tipo": "receita" | "despesa" | "conversa",
    "categoria": "alimentaÃ§Ã£o" | "transporte" | "moradia" | "lazer" | "salÃ¡rio" | "freelance" | "outro",
    "valor": nÃºmero ou null,
    "descricao": "descriÃ§Ã£o curta"
}}

Se nÃ£o for uma transaÃ§Ã£o financeira, use tipo="conversa".
"""
        
        try:
            if self.current_provider == AIProvider.OLLAMA:
                resposta = await self.ollama.generate(
                    prompt_classificacao,
                    system="VocÃª Ã© um classificador de transaÃ§Ãµes. Responda APENAS com JSON vÃ¡lido."
                )
            elif self.current_provider == AIProvider.GROQ:
                resposta = await self.groq.generate(
                    prompt_classificacao,
                    system="VocÃª Ã© um classificador de transaÃ§Ãµes. Responda APENAS com JSON vÃ¡lido."
                )
            else:
                # Fallback: tentar extrair padrÃµes simples
                return self._classificar_fallback(texto)
            
            # Tentar parsear JSON da resposta
            # Limpar possÃ­veis caracteres extras
            resposta = resposta.strip()
            if resposta.startswith("```"):
                resposta = resposta.split("```")[1]
                if resposta.startswith("json"):
                    resposta = resposta[4:]
            
            return json.loads(resposta)
            
        except Exception as e:
            print(f"âš ï¸ Erro na classificaÃ§Ã£o: {e}")
            return self._classificar_fallback(texto)
    
    def _classificar_fallback(self, texto: str) -> Dict:
        """ClassificaÃ§Ã£o por padrÃµes quando IA nÃ£o estÃ¡ disponÃ­vel"""
        texto_lower = texto.lower()
        
        # PadrÃµes de gasto
        palavras_gasto = ["gastei", "paguei", "comprei", "gasto", "despesa", "conta"]
        palavras_receita = ["recebi", "ganhei", "entrou", "salÃ¡rio", "freelance", "pagamento"]
        
        # Extrair valor (padrÃ£o: R$ ou nÃºmero solto)
        import re
        valor_match = re.search(r'R?\$?\s*(\d+(?:[.,]\d{2})?)', texto)
        valor = float(valor_match.group(1).replace(',', '.')) if valor_match else None
        
        # Determinar tipo
        if any(p in texto_lower for p in palavras_gasto):
            tipo = "despesa"
        elif any(p in texto_lower for p in palavras_receita):
            tipo = "receita"
        else:
            tipo = "conversa"
        
        # Categorias bÃ¡sicas
        categorias = {
            "ifood": "alimentaÃ§Ã£o", "comida": "alimentaÃ§Ã£o", "almoÃ§o": "alimentaÃ§Ã£o",
            "uber": "transporte", "Ã´nibus": "transporte", "gasolina": "transporte",
            "aluguel": "moradia", "luz": "moradia", "Ã¡gua": "moradia",
            "netflix": "lazer", "cinema": "lazer", "jogo": "lazer",
            "salÃ¡rio": "salÃ¡rio", "freelance": "freelance"
        }
        
        categoria = "outro"
        for palavra, cat in categorias.items():
            if palavra in texto_lower:
                categoria = cat
                break
        
        return {
            "tipo": tipo,
            "categoria": categoria,
            "valor": valor,
            "descricao": texto[:50]
        }


# Singleton para uso global
ai_service = AIService()


# ============================================
# ðŸš€ FUNÃ‡Ã•ES DE CONVENIÃŠNCIA
# ============================================

async def get_ai_response(
    mensagem: str,
    saldo: float = 0,
    divida: float = 0,
    ultimo_gasto: float = None
) -> str:
    """
    FunÃ§Ã£o simplificada para obter resposta da IA
    """
    contexto = {
        "saldo_atual": saldo,
        "divida_total": divida
    }
    
    if ultimo_gasto and divida > 0:
        from app.services.financial_engine import FinancialEngine
        from decimal import Decimal
        
        impacto = FinancialEngine.calcular_impacto_gasto(
            Decimal(str(divida)),
            Decimal(str(divida * 0.1)),  # 10% da dÃ­vida como pagamento
            Decimal("0.05"),
            Decimal(str(ultimo_gasto))
        )
        contexto["impacto"] = impacto
    
    resultado = await ai_service.processar_mensagem(mensagem, contexto)
    return resultado["resposta"]
